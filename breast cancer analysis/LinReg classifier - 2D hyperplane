# graph factors using a linear regression to create a linear classifier (2D hyperplane)
def graphLinReg(x, y, xLabel, yLabel, x_df, y_df):
    plt.scatter(x, y, color='red') # differentiate between red slope and blue points

    # use DataFrame to label the axes
    plt.xlabel('%s' % xLabel)
    plt.ylabel('%s' % yLabel)
    plt.title('%s vs. %s' % (yLabel, xLabel))

    z = np.polyfit(x, y, 1) # create a 1D polynomial (i.e. line)
    f = np.poly1d(z) # create a function with respect to the polynomial line, to which we can plug in inputs
    plt.plot(x, f(x)) # plot y by using f(x) for the artificial (rather than natural) y points

    # calculate mean sum squared error (not actually squared, mse refers to distance, not displacement)
    mseSum = 0
    for i in range(len(x)):  # iterate through all elements (every single patient)
        mse = np.mean(np.sqrt((x[i] - f(x)) ** 2))  # takes average of abs(difference) of (individual dot - trend line)
        mseSum += mse
    print("Total mean sum squared error: " + str(round(mseSum, 4)))  # total error for all points to the trend line

    # use DataFrame for the regression, while using X.columns[0] or [1] for the actual label and string text
    regression = linear_model.LinearRegression()
    regression.fit(x_df, y_df)

    y_int = round(regression.intercept_, 4)
    x_coefficient = round(float(regression.coef_), 4) # use type float for more accurate slope calculations

    # use sympy modules
    x = sympy.Symbol('x')
    yFn = x_coefficient * x + y_int

    print("\nY-intercept: %s" % y_int)
    print("Coefficient: %s" % x_coefficient)
    print("Trend line equation: %s" % yFn)

    plt.show()

df_svm_linReg = pd.DataFrame(factors, columns=['Mean area', 'Mean compactness', 'Mean texture',
                                    'Mean concavity', 'Mean radius', 'Mean perimeter',
                                    'Mean smoothness', 'Mean concave points', 'Mean symmetry',
                                    'Mean fractal dimensions', 'Diagnosis'])

parameterStrings = ['Mean area', 'Mean compactness', 'Mean texture', 'Mean concavity', 'Mean radius', 'Mean perimeter',
    'Mean smoothness', 'Mean concave points', 'Mean symmetry', 'Mean fractal dimensions']

# create new random numbers for LinReg
parameter1_LinReg = randint(0,9)
parameter2_LinReg = randint(0,9)
while parameter1_LinReg == parameter2_LinReg:
    parameter1_LinReg = randint(0,9)
    parameter2_LinReg = randint(0,9)
    if parameter1_LinReg != parameter2_LinReg:
        break
        
# use array of all attributes with random number index to access relevant data
xGraphLinReg = indVars[parameter1_LinReg]
yGraphLinReg = indVars[parameter2_LinReg]

# use DataFrame to access the labels for each axis
X = df_svm_linReg[[parameterStrings[parameter1_LinReg], parameterStrings[parameter2_LinReg]]]

# use DataFrame labels to pass to graphing function and create DataFrame to use for regression
xLabel_LinReg = X.columns[0]
yLabel_LinReg = X.columns[1]

xDF_LinReg = df_svm_linReg[[parameterStrings[parameter1_LinReg]]] # use 2D array for x DataFrame, needed for regression
yDF_LinReg = df_svm_linReg[parameterStrings[parameter2_LinReg]]

graphLinReg(xGraphLinReg, yGraphLinReg, xLabel_LinReg, yLabel_LinReg, xDF_LinReg, yDF_LinReg)
